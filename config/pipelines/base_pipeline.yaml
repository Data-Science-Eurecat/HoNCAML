data:
  extract:
    filepath: data/raw/dataset.csv
    # If features key does not exist, the pipeline gets all columns as features
    features:
      - col1
      - col2
    target:
      - target1
      - target2
    # pandas read files additional params
    dtype:
      col1: int
      col2: int

  transform:
    normalize:
      features:
        module: sklearn.preprocessing.StandardScaler
        module_params:
          with_std: True
        columns:
          - col1
          - col2
      target:
        module: sklearn.preprocessing.StandardScaler
        columns:
          - target1
          - target2

# load:
# filepath: data/processed/dataset.csv

benchmark:
  transform:
    tuner:
      algorithm: ray.tune.search.optuna.OptunaSearch
        # TODO (future): paràmetres de l'algorisme de cerca
      # TODO (future): + paràmetres del tuner
      # TODO (future): tune_config:
      # TODO (future): run_config:
    
    # TODO (future): schedulers:
    # TODO (future): callbacks:
    
    models:
      - module: sklearn.ensemble.RandomForestRegressor
        search_space:
          n_estimators:
            method: randint # TODO: mapping search spaces
            value: [2, 10]
          
      - module: sklearn.linear_model.LinearRegression
        search_space:
          fit_intercept:
            method: choice
            value: [True, False]
    
    cross_validation:
      strategy: k_fold
      n_splits: 10
      shuffle: True
      random_state: 90


# Model Step settings
model:
  estimator_type: regressor # | classifier
  estimator_config:
    module: sklearn.ensemble.RandomForestRegressor
    hyperparameters:
      n_estimators: 100

  extract:
    filepath: models/sklearn.regressor.20220819-122417.sav

  transform:
    fit: # | predict
      cross_validation:
        strategy: k_fold
        # Additional arguments of sklearn cross-validation objects
        n_splits: 10
        random_seed: 90

  load:
    path: models/

  # Benchmark Step settings

<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Configuration &#8212; HoNCAML 0.2.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=6e26af7d" />
    <script src="_static/documentation_options.js?v=938c9ccc"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Reference" href="reference.html" />
    <link rel="prev" title="Usage" href="usage.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="configuration">
<span id="id1"></span><h1>Configuration<a class="headerlink" href="#configuration" title="Link to this heading">¶</a></h1>
<p>The main difference between the use case of regular users compared to advanced
users is reflected in the configuration of the pipeline.</p>
<p>Conceptually, a pipeline is composed from a modular composition of steps. The
ones available are the following:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#data-step"><span class="std std-ref">Data</span></a>: Responsible for raw data management</p></li>
<li><p><a class="reference internal" href="#model-step"><span class="std std-ref">Model</span></a>: Responsible for model management</p></li>
<li><p><a class="reference internal" href="#benchmark-step"><span class="std std-ref">Benchmark</span></a>: Responsible for searching the best model configuration</p></li>
</ul>
<p>The configuration should be done through a <a class="reference external" href="https://yaml.org/spec/">YAML</a>
file, which contains all the pipeline and steps options that are considered.</p>
<section id="global">
<h2>Global<a class="headerlink" href="#global" title="Link to this heading">¶</a></h2>
<p>First of all, it is necessary to specify global options, which are the
following:</p>
<ul class="simple">
<li><p>problem_type: The kind of problem that determines the model/s to use. Valid
values are: <code class="docutils literal notranslate"><span class="pre">classification</span></code>, <code class="docutils literal notranslate"><span class="pre">regression</span></code>.</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">global</span><span class="p">:</span>
<span class="w">    </span><span class="nt">problem_type</span><span class="p">:</span>
</pre></div>
</div>
<p>Afterwards, the steps configuration is provided, which is detailed below.</p>
</section>
<section id="data">
<span id="data-step"></span><h2>Data<a class="headerlink" href="#data" title="Link to this heading">¶</a></h2>
<p>This step is made up of the following ETL phases:</p>
<ol class="arabic simple">
<li><p><strong>extract</strong>: Read the raw data.</p></li>
<li><p><strong>transform</strong>: Apply a set of data transformations, e.g. normalization, rename
columns, etc.</p></li>
<li><p><strong>load</strong>: Save the processed dataset.</p></li>
</ol>
<p>Example of data step in a pipeline file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">data</span><span class="p">:</span>
<span class="w">    </span><span class="nt">extract</span><span class="p">:</span>
<span class="w">      </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">data/raw/dataset.csv</span>
<span class="w">      </span><span class="nt">features</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bedrooms</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bathrooms</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sqft_living</span>
<span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">price</span>

<span class="w">    </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">      </span><span class="nt">normalize</span><span class="p">:</span>
<span class="w">        </span><span class="nt">features</span><span class="p">:</span>
<span class="w">          </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sklearn.preprocessing.StandardScaler</span>
<span class="w">        </span><span class="nt">target</span><span class="p">:</span>
<span class="w">          </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sklearn.preprocessing.StandardScaler</span>

<span class="w">    </span><span class="nt">load</span><span class="p">:</span>
<span class="w">        </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">data/processed/dataset.</span>
</pre></div>
</div>
<section id="extract">
<h3>Extract<a class="headerlink" href="#extract" title="Link to this heading">¶</a></h3>
<p>In the extract phase the possible configurations are the following:</p>
<ul class="simple">
<li><p><strong>filepath</strong> (str, optional): File path of dataset to use. It is an
optional param. The default value is <code class="docutils literal notranslate"><span class="pre">data/raw/dataset.csv</span></code>.</p></li>
<li><p><strong>target</strong> (str): Column name as a target.</p></li>
<li><p><strong>features</strong> (list, optional): Set of columns to process. It is an optional
param. When <em>features</em> is not indicated, the process uses all columns.</p></li>
</ul>
<section id="examples">
<h4>Examples:<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h4>
<p>In the following example, the framework reads dataset from
<code class="docutils literal notranslate"><span class="pre">data/raw/boston_dataset.csv</span></code>. Also, it gets <code class="docutils literal notranslate"><span class="pre">price</span></code> column as a target.
In addition, it uses <code class="docutils literal notranslate"><span class="pre">bedrooms</span></code>, <code class="docutils literal notranslate"><span class="pre">bathrooms</span></code>, <code class="docutils literal notranslate"><span class="pre">sqft_living</span></code> as features.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">extract</span><span class="p">:</span>
<span class="w">  </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">data/raw/boston_dataset.csv</span>
<span class="w">  </span><span class="nt">features</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bedrooms</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bathrooms</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sqft_living</span>
<span class="w">  </span><span class="nt">target</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">price</span>
</pre></div>
</div>
</section>
</section>
<section id="transform">
<h3>Transform<a class="headerlink" href="#transform" title="Link to this heading">¶</a></h3>
<p>In this phase the possible transformations are the following:</p>
<section id="encoding">
<h4>Encoding<a class="headerlink" href="#encoding" title="Link to this heading">¶</a></h4>
<p>The parameter <strong>encoding</strong> (dict, optional) defines the dataset encoding for
categorical features through <em>One Hot Encoding</em> (OHE) method. This is defined
through two additional parameters within the <strong>encoding</strong> dictionary, which are
<strong>OHE</strong> (boolean), which determines whether to apply the encoding to features
or not, and <strong>features</strong> (list/str, optional), that specify the feature or
features to apply OHE to; if empty and <strong>OHE</strong> is True, OHE would be applied to
all categorical features from the dataset, except for the target.</p>
</section>
<section id="id2">
<h4>Examples<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h4>
<p>The simplest configuration is the following, which means a OHE for all
the categorical features:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
</pre></div>
</div>
<p>The following example, the framework applies OHE for all categorical features:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">encoding</span><span class="p">:</span>
<span class="w">   </span><span class="nt">OHE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
</pre></div>
</div>
<p>The opposite case would be to not apply OHE to any feature:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">encoding</span><span class="p">:</span>
<span class="w">   </span><span class="nt">OHE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
</pre></div>
</div>
<p>Another example is then OHE should be applied only to specific features. In the
following example, OHE is applied only to columns <em>column_a</em> and <em>column_b</em>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">encoding</span><span class="p">:</span>
<span class="w">   </span><span class="nt">OHE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">   </span><span class="nt">features</span><span class="p">:</span>
<span class="w">     </span><span class="l l-Scalar l-Scalar-Plain">column_a</span>
<span class="w">     </span><span class="l l-Scalar l-Scalar-Plain">column_b</span>
</pre></div>
</div>
</section>
<section id="normalize">
<h4>Normalize<a class="headerlink" href="#normalize" title="Link to this heading">¶</a></h4>
<p>The parameter <strong>normalize</strong> (dict, optional) defines the dataset
normalization. It is possible to normalize nothing, features, target or
both. With <strong>features</strong> parameter, it defines which normalization apply to
features. Furthermore, with <strong>target</strong> parameter, it defines the target
normalization. If the transform step contains an empty <strong>normalize</strong> key, it
uses a <code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code> for features and target as
default. On the other hand, if <strong>normalize</strong> key does not exist, no
normalization is applied. If only features or target (but not both) are to be
normalized, empty settings should be provided for the part that does not
require normalization.</p>
<ul class="simple">
<li><p><strong>target</strong> (list, optional): Column name as a target. It is an
optional param. The default value is <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p></li>
<li><p><strong>features</strong> (list, optional): Set of columns to process. It is an
optional param. When empty, the process uses all columns.</p></li>
</ul>
<p>For any of the previous mentioned, there are three children keys:</p>
<ul class="simple">
<li><p><strong>module</strong> (str, optional): Normalization module to apply. Right now,
<code class="docutils literal notranslate"><span class="pre">sklean.preprocessing.StandardScaler</span></code> is the only one supported.</p></li>
<li><p><strong>params</strong> (dict, optional): Specific parameters of the previous
module. Should be specified as key-value pairs.</p></li>
<li><p><strong>columns</strong> (list, optional): Columns to be considered for normalization. By
default, all of features/target if empty, depending on the context.</p></li>
</ul>
</section>
<section id="id3">
<h4>Examples<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h4>
<p>The simplest configuration is the following, which means no normalization:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
</pre></div>
</div>
<p>In the example below, the framework applies a default normalization parameters
(<code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code> for both target and features).</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">normalize</span><span class="p">:</span>
</pre></div>
</div>
<p>If only features or target are to be normalized, just an empty module should be
provided for target.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">normalize</span><span class="p">:</span>
<span class="w">    </span><span class="nt">target</span><span class="p">:</span>
<span class="w">      </span><span class="nt">module</span><span class="p">:</span>
</pre></div>
</div>
<p>In the example below, the framework uses a
<code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code> for normalize target and
features. In the case of features, normalization is applied considering std,
and only for columns named <em>column_a</em> and <em>column_b</em>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">normalize</span><span class="p">:</span>
<span class="w">    </span><span class="nt">features</span><span class="p">:</span>
<span class="w">      </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sklearn.preprocessing.StandardScaler</span>
<span class="w">      </span><span class="nt">params</span><span class="p">:</span>
<span class="w">        </span><span class="nt">with_std</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">        </span><span class="nt">columns</span><span class="p">:</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">column_a</span>
<span class="w">          </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">column_b</span>
</pre></div>
</div>
</section>
</section>
<section id="load">
<h3>Load<a class="headerlink" href="#load" title="Link to this heading">¶</a></h3>
<p>In load phase the possible configurations are the following:</p>
<ul class="simple">
<li><p><strong>filepath</strong> (str, optional): file path to store processed dataset.</p></li>
</ul>
<section id="id4">
<h4>Examples<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h4>
<p>The simplest configuration is the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">load</span><span class="p">:</span>
</pre></div>
</div>
<p>When <strong>load</strong> phase is empty, the framework does not save the processed
dataset.</p>
<p>The following example, the framework stores the processed data in
<code class="docutils literal notranslate"><span class="pre">data/processed/dataset.csv</span></code>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">load</span><span class="p">:</span>
<span class="w">  </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">data/processed/dataset.csv</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="model">
<span id="model-step"></span><h2>Model<a class="headerlink" href="#model" title="Link to this heading">¶</a></h2>
<p>This step is responsible for model management.</p>
<p>It is made up for the following ETL phases:</p>
<ul class="simple">
<li><p><strong>extract</strong>: The purpose of this phase is to read a previously saved model.</p></li>
<li><p><strong>transform</strong>: This phase applies the common model functions:
training, testing and cross-validation.</p></li>
<li><p><strong>load</strong>: Saves the initialized model.</p></li>
</ul>
<section id="id5">
<h3>Extract<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h3>
<p>In extract phase the possible configurations are the following:</p>
<ul class="simple">
<li><p><strong>filepath</strong> (str <a class="footnote-reference brackets" href="#comp1" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>): File path of model to read.</p></li>
</ul>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="comp1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">1</a><span class="fn-bracket">]</span></span>
<p>Compulsory for predict pipelines, and excluded in the rest of pipeline types.</p>
</aside>
</aside>
</section>
<section id="id7">
<h3>Transform<a class="headerlink" href="#id7" title="Link to this heading">¶</a></h3>
<p>This phase applies the common model functions: fit, predict and
cross-validation. The available configurations are the following:</p>
<ul>
<li><p><strong>fit</strong> (dict <a class="footnote-reference brackets" href="#comp2" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>): Requests a model training on the current dataset. It
may have the following additional information:</p>
<ul>
<li><p><strong>estimator</strong> (dict, optional): Sppecifies the estimator and its
hyperparameters. Consists of the following:</p>
<ul class="simple">
<li><p><strong>module</strong> (str, optional): Learner module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module
class.</p></li>
</ul>
<p>Available models are the ones <a class="reference external" href="https://scikit-learn.org/stable/supervised_learning.html">available from sklearn</a>, and of
course just the ones related to the problem type specified.
Default models are <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code> for
regression and <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier</span></code> for
classification problems, both with <code class="docutils literal notranslate"><span class="pre">n_estimator</span></code> equal to 100.</p>
</li>
<li><p><strong>cross_validation</strong> (dict, optional): Defines which cross-validation
strategy to use for training the model. Dictionary may have the following
keys:</p>
<ul class="simple">
<li><p><strong>module</strong> (str, optional): Cross validation module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module
class.</p></li>
</ul>
<p>Any cross validation method in <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators">sklearn cross-validation</a>
should work, provided that it follows their consistent structure.
Default: <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.KFold</span></code> with 3 splits.</p>
</li>
<li><p><strong>metrics</strong> (list): a list of metrics to evaluate the model.
Any metric that exists in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">sklearn.metrics</a>
is allowed, of course that apply to the problem type; only the function
name is required.  Default values are <code class="docutils literal notranslate"><span class="pre">mean_squared_error</span></code>,
<code class="docutils literal notranslate"><span class="pre">mean_absolute_percentage_error</span></code>, <code class="docutils literal notranslate"><span class="pre">median_absolute_error</span></code>,
<code class="docutils literal notranslate"><span class="pre">mean_absolute_error</span></code>, <code class="docutils literal notranslate"><span class="pre">root_mean_squared_error</span></code> for regression
problems and <code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code>, <code class="docutils literal notranslate"><span class="pre">precision_score</span></code>, <code class="docutils literal notranslate"><span class="pre">recall_score</span></code>,
<code class="docutils literal notranslate"><span class="pre">specificity_score</span></code>, <code class="docutils literal notranslate"><span class="pre">f1_score</span></code> and <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code> for
classification problems.</p>
<p>It is even possible to define custom metrics. For this, what is needed just
to define a function named <code class="docutils literal notranslate"><span class="pre">compute_{metric_name}_metric</span></code> in the file
<code class="docutils literal notranslate"><span class="pre">honcaml/models/evaluate.py</span></code>, being {metric_name} the name of the
metric, and having as input parameters the series of true values, and the
series of predicted ones, in this order (there are already a couple of
examples). Then, it is just a matter of include the metric name in the
configuration.</p>
<p>Both options have the possibility to pass additional parameters to the
metric function, by specifying the metric as a dictionary instead of a
single string. The dictionary key would be the metric name, whereas its
values would refer to function parameters.</p>
</li>
</ul>
</li>
<li><p><strong>predict</strong> (dict <a class="footnote-reference brackets" href="#comp3" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>): Requests to run predictions over the dataset.</p>
<ul class="simple">
<li><p><strong>path</strong> (str, optional): Directory where the predictions will be
stored. Default value: <code class="docutils literal notranslate"><span class="pre">data/processed</span></code>.</p></li>
</ul>
</li>
</ul>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="comp2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">2</a><span class="fn-bracket">]</span></span>
<p>Compulsory for fit pipelines, and excluded for predict pipelines. Related to
benchmark pipelines, see the details in <a class="reference internal" href="#benchmark-step"><span class="std std-ref">Benchmark</span></a>.</p>
</aside>
<aside class="footnote brackets" id="comp3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">3</a><span class="fn-bracket">]</span></span>
<p>Compulsory for predict pipelines, and excluded for the rest of pipeline
types.</p>
</aside>
</aside>
<section id="id10">
<h4>Examples<a class="headerlink" href="#id10" title="Link to this heading">¶</a></h4>
<p>The following snippet shows an example of an advanced model transform
definition:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">fit</span><span class="p">:</span>
<span class="w">    </span><span class="nt">estimator</span><span class="p">:</span>
<span class="w">      </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sklearn.ensemble.RandomForestRegressor</span>
<span class="w">      </span><span class="nt">params</span><span class="p">:</span>
<span class="w">        </span><span class="nt">n_estimators</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
<span class="w">    </span><span class="nt">cross_validation</span><span class="p">:</span>
<span class="w">      </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sklearn.model_selection.KFold</span>
<span class="w">      </span><span class="nt">params</span><span class="p">:</span>
<span class="w">        </span><span class="nt">n_splits</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
</pre></div>
</div>
</section>
<section id="deep-learning-models">
<span id="id11"></span><h4>Deep learning models<a class="headerlink" href="#deep-learning-models" title="Link to this heading">¶</a></h4>
<p>Deep learning models implemented in torch require a specific format, different
from sklearn based models or similar, in which parameters are passed directly
when instantiating the model class.</p>
<p>First of all, <strong>module</strong> key should have just as value <code class="docutils literal notranslate"><span class="pre">torch</span></code> in order to
indicate that a neural net will be used as estimator. Within the <strong>params</strong>
key, the following keys should be specified <a class="footnote-reference brackets" href="#comp4" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>:</p>
<ul>
<li><p><strong>epochs</strong> (int): Number of training epochs.</p></li>
<li><p><strong>layers</strong> (list) Layers configuration; the structure of each one is:</p>
<ul class="simple">
<li><p><strong>module</strong> (str): Layer module to use.</p></li>
<li><p><strong>params</strong> (dict, optional <a class="footnote-reference brackets" href="#comp5" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a>): Additional parameters to pass to
layers.</p></li>
</ul>
<p>In the case of linear layers, as the parameter <strong>in_features</strong> is dependent
on previous layers, only <strong>out_features</strong> is required; however, if the last
layer of the neural net is another linear layer, no <strong>out_features</strong> should
be provided, as dimension will be inferred from targets.</p>
</li>
<li><p><strong>loader</strong>: (dict): Specifies data loader options to use. Internal keys:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>batch_size</strong> (int): Number of rows to consider for each batch.</p></li>
<li><p><strong>shuffle</strong> (bool): Whether to shuffle data at every epoch.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>loss</strong> (dict): Loss to consider; requires the following:</p>
<ul class="simple">
<li><p><strong>module</strong> (str): Loss module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module.</p></li>
</ul>
</li>
<li><p><strong>optimizer</strong> (dict): Optimizer to consider; requires the following:</p>
<ul class="simple">
<li><p><strong>module</strong> (str): Optimizer module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module.</p></li>
</ul>
</li>
</ul>
<p>An example of a training configuration for a deep learning model would be:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">    </span><span class="nt">fit</span><span class="p">:</span>
<span class="w">      </span><span class="nt">estimator</span><span class="p">:</span>
<span class="w">        </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch</span>
<span class="w">        </span><span class="nt">params</span><span class="p">:</span>
<span class="w">          </span><span class="nt">epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">          </span><span class="nt">layers</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.Linear</span>
<span class="w">              </span><span class="nt">params</span><span class="p">:</span>
<span class="w">                </span><span class="nt">out_features</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.ReLU</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.Linear</span>
<span class="w">              </span><span class="nt">params</span><span class="p">:</span>
<span class="w">                </span><span class="nt">out_features</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.Dropout</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.Linear</span>
<span class="w">          </span><span class="nt">loader</span><span class="p">:</span>
<span class="w">            </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>
<span class="w">            </span><span class="nt">shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">          </span><span class="nt">loss</span><span class="p">:</span>
<span class="w">            </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.MSELoss</span>
<span class="w">          </span><span class="nt">optimizer</span><span class="p">:</span>
<span class="w">            </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.optim.SGD</span>
<span class="w">            </span><span class="nt">params</span><span class="p">:</span>
<span class="w">              </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.001</span>
<span class="w">              </span><span class="nt">momentum</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.9</span>
</pre></div>
</div>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="comp4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">4</a><span class="fn-bracket">]</span></span>
<p>All options are required for training and benchmark pipelines, whereas
dataloader is the only one required by predict pipelines.</p>
</aside>
<aside class="footnote brackets" id="comp5" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">5</a><span class="fn-bracket">]</span></span>
<p>Optional for all layer types except for linear ones, except for the last
layer if it is linear.</p>
</aside>
</aside>
</section>
</section>
<section id="id14">
<h3>Load<a class="headerlink" href="#id14" title="Link to this heading">¶</a></h3>
<p>In load phase the possible configurations are the following:</p>
<ul class="simple">
<li><p><strong>filepath</strong> (str, required): Directory and file name where the model will be saved.
If the user specifies the file name as <code class="docutils literal notranslate"><span class="pre">{autogenerate}.sav</span></code>, the filename is
generated by the framework following the following
convention: <code class="docutils literal notranslate"><span class="pre">{model_type}.{execution_id}.sav</span></code>
Otherwise, if the user specifies a custom name, the file is saved with that name.
The supported formats for saving a model include the extension <code class="docutils literal notranslate"><span class="pre">.sav</span></code></p></li>
<li><p><strong>results</strong> (str, <a class="footnote-reference brackets" href="#comp6" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>): Directory where to store training cross
validation results; generated file will have the following format:
<code class="docutils literal notranslate"><span class="pre">{results}/{execution_id}/results.csv</span></code>. If not set, results will not be
exported.</p></li>
</ul>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="comp6" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">6</a><span class="fn-bracket">]</span></span>
<p>Optional for train pipelines, and excluded for the rest of pipeline
types.</p>
</aside>
</aside>
</section>
</section>
<section id="benchmark">
<span id="benchmark-step"></span><h2>Benchmark<a class="headerlink" href="#benchmark" title="Link to this heading">¶</a></h2>
<p>This step is responsible for searching the best model configuration.</p>
<p>It is made up for the following ETL phases:</p>
<ul class="simple">
<li><p><strong>transform</strong>: this phase runs an hyperparamater search algorithm for each
specified model. Furthermore, it gets the best model configuration.</p></li>
<li><p><strong>load</strong>: it saves the best configuration into a yaml file.</p></li>
</ul>
<p>Apart from obtaining the best model configuration, it is possible to train the
best model through appending a model key after the benchmark step, taking
advantage of the modular definition of the solution:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="w"> </span><span class="nt">global</span><span class="p">:</span>
<span class="w">   </span><span class="nt">problem_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">regression</span>

<span class="w"> </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">   </span><span class="nt">data</span><span class="p">:</span>
<span class="w">     </span><span class="nt">extract</span><span class="p">:</span>
<span class="w">       </span><span class="nt">filepath</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{</span><span class="nv">Input data</span><span class="p p-Indicator">}</span>
<span class="w">       </span><span class="nt">target</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{</span><span class="nv">Target</span><span class="p p-Indicator">}</span>

<span class="nt">benchmark</span><span class="p">:</span>
<span class="w">  </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">  </span><span class="nt">load</span><span class="p">:</span>
<span class="w">    </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{</span><span class="nv">gReports path</span><span class="p p-Indicator">}</span>

<span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">    </span><span class="nt">fit</span><span class="p">:</span>
<span class="w">  </span><span class="nt">load</span><span class="p">:</span>
<span class="w">    </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{</span><span class="nv">Path to store best model</span><span class="p p-Indicator">}</span>
</pre></div>
</div>
<section id="id16">
<h3>Transform<a class="headerlink" href="#id16" title="Link to this heading">¶</a></h3>
<p>This phase runs an hyperparameter search algorithm for each model defined in
pipeline file. Furthermore, the user can define a set of metrics to evaluate
the experiments, the model’s hyperparamaters to tune, the strategy to split
train and test data and parameters of search algorithm.</p>
<p>The available configurations are the following:</p>
<ul>
<li><p><strong>models</strong> (dict, optional): Dictionary of models and hyperparameters to
search for best configuration. Each entry of the list refers to a model to
benchmark. Keys should be the following:</p>
<ul class="simple">
<li><p><strong>{model_name}</strong> (dict, optional): Name of model module,
e.g. <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code>.</p></li>
</ul>
<p>Within each module, there should be as many keys as model parameters to
search:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>{hyperparameter}</strong> (dict, optional): Name of hyperparameter,
e.g. <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>. Within each hyperparameter, the following needs to
be specified:</p>
<ul>
<li><p><strong>method</strong> (str, optional): Method to consider for searching
hyperparameter values.</p></li>
<li><p><strong>values</strong> (tuple/list, optional): Values to consider for hyperparameter
search, passed to specified method.</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<p>Available methods and value parameters are defined in the <a class="reference external" href="https://docs.ray.io/en/latest/tune/api/search_space.html">search space</a>.  The default
models and hyperparameters for each type of problem are defined at
<em>honcaml/config/defaults/search_spaces.py</em>.</p>
<p>In case of deep learning models, the name of the model to use is <code class="docutils literal notranslate"><span class="pre">torch</span></code>,
and there is a specific chapter to detail the required configuration in
<a class="reference internal" href="#deep-learning-benchmark"><span class="std std-ref">Deep learning benchmark</span></a>.</p>
</li>
<li><p><strong>cross_validation</strong> (dict, optional): defines which cross-validation
strategy to use for training each model. Dictionary may have the following
keys:</p>
<ul class="simple">
<li><p><strong>module</strong> (str, optional): Cross validation module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module class.</p></li>
</ul>
<p>Any cross validation method in <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators">sklearn cross-validation</a>
should work, provided that it follows their consistent structure.
Default: <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.KFold</span></code> with 3 splits.</p>
</li>
<li><p><strong>metrics</strong> (list/str, optional): a list of metrics to report in the
benchmark process, or a single one. Actually, reported metrics may be
appended with the one specified in tuner settings, if the latter is different
(as it is the one used to select the best model configuration). Any metric
that exists in <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">sklearn.metrics</a>
is allowed, of course that apply to the problem type; only the function name
is required.  Default values are <code class="docutils literal notranslate"><span class="pre">mean_squared_error</span></code>,
<code class="docutils literal notranslate"><span class="pre">mean_absolute_percentage_error</span></code>, <code class="docutils literal notranslate"><span class="pre">median_absolute_error</span></code>,
<code class="docutils literal notranslate"><span class="pre">mean_absolute_error</span></code>, <code class="docutils literal notranslate"><span class="pre">root_mean_squared_error</span></code> for regression problems
and <code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code>, <code class="docutils literal notranslate"><span class="pre">precision_score</span></code>, <code class="docutils literal notranslate"><span class="pre">recall_score</span></code>,
<code class="docutils literal notranslate"><span class="pre">specificity_score</span></code>, <code class="docutils literal notranslate"><span class="pre">f1_score</span></code> and <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code> for classification
problems.</p>
<p>It is even possible to define custom metrics. For this, what is needed just
to define a function named <code class="docutils literal notranslate"><span class="pre">compute_{metric_name}_metric</span></code> in the file
<code class="docutils literal notranslate"><span class="pre">honcaml/models/evaluate.py</span></code>, being {metric_name} the name of the
metric, and having as input parameters the series of true values, and the
series of predicted ones, in this order (there are already a couple of
examples). Then, it is just a matter of include the metric name in the
configuration.</p>
</li>
<li><p><strong>tuner</strong> (dict): defines the configuration of tune process. Their options
are the following:</p>
<ul class="simple">
<li><p><strong>search_algorithm</strong> (dict, optional): Specifies the algorithm to perform
the search. Consists of the following:</p>
<ul>
<li><p><strong>module</strong> (str, optional): Algorithm module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module
class.</p></li>
</ul>
</li>
</ul>
<p>For all available options, see <a class="reference external" href="https://docs.ray.io/en/latest/tune/api/suggestion.html">the search algorithms documentation</a>.
Default is <code class="docutils literal notranslate"><span class="pre">ray.tune.search.optuna.OptunaSearch</span></code>.</p>
<ul class="simple">
<li><p><strong>tune_config</strong> (dict, optional): Parameters to pass to tuner config
object, specified as key-value pairs. For available options, see <a class="reference external" href="https://docs.ray.io/en/latest/tune/api/doc/ray.tune.TuneConfig.html">TuneConfig
documentation</a>.</p></li>
<li><p><strong>run_config</strong> (dict, optional): Parameters to be used during run,
specified as key-value pairs. For available options, see <a class="reference external" href="https://docs.ray.io/en/latest/ray-air/api/doc/ray.air.RunConfig.html">RunConfig
documentation</a>.</p></li>
<li><p><strong>scheduler</strong> (dict, optional): Allows to define different strategies
during the search process. Consists of the following:</p>
<ul>
<li><p><strong>module</strong> (str, optional): Algorithm module to use.</p></li>
<li><p><strong>params</strong> (dict, optional): Additional parameters to pass to module
class.</p></li>
</ul>
</li>
</ul>
<p>For all available options, see <a class="reference external" href="https://docs.ray.io/en/latest/tune/api/schedulers.html">schedulers documentation</a>.</p>
</li>
</ul>
<section id="id19">
<h4>Examples<a class="headerlink" href="#id19" title="Link to this heading">¶</a></h4>
<p>The following snippet shows an example of an advanced benchmark transform
definition:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">metrics</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mean_squared_error</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mean_absolute_error</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">root_mean_square_error</span>
<span class="nt">models</span><span class="p">:</span>
<span class="w">  </span><span class="nt">sklearn.ensemble.RandomForestRegressor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">n_estimators</span><span class="p">:</span>
<span class="w">      </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">randint</span>
<span class="w">      </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">110</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">max_features</span><span class="p">:</span>
<span class="w">      </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">choice</span>
<span class="w">      </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">sqrt</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">log2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1</span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">sklearn.linear_model.LinearRegression</span><span class="p">:</span>
<span class="w">    </span><span class="nt">fit_intercept</span><span class="p">:</span>
<span class="w">      </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">choice</span>
<span class="w">      </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">True</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">False</span><span class="p p-Indicator">]</span>
<span class="nt">cross_validation</span><span class="p">:</span>
<span class="w">  </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sklearn.model_selection.KFold</span>
<span class="w">  </span><span class="nt">params</span><span class="p">:</span>
<span class="w">    </span><span class="nt">n_splits</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="nt">tuner</span><span class="p">:</span>
<span class="w">  </span><span class="nt">search_algorithm</span><span class="p">:</span>
<span class="w">    </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ray.tune.search.optuna.OptunaSearch</span>
<span class="w">  </span><span class="nt">tune_config</span><span class="p">:</span>
<span class="w">    </span><span class="nt">num_samples</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">metric</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">root_mean_squared_error</span>
<span class="w">    </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">min</span>
<span class="w">  </span><span class="nt">run_config</span><span class="p">:</span>
<span class="w">    </span><span class="nt">stop</span><span class="p">:</span>
<span class="w">      </span><span class="nt">training_iteration</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">  </span><span class="nt">scheduler</span><span class="p">:</span>
<span class="w">    </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ray.tune.schedulers.HyperBandScheduler</span>
</pre></div>
</div>
</section>
<section id="deep-learning-benchmark">
<span id="id20"></span><h4>Deep learning benchmark<a class="headerlink" href="#deep-learning-benchmark" title="Link to this heading">¶</a></h4>
<p>Deep learning models, in a benchmark pipeline, require a specific format, due
to the fact that models require a custom format as well (it is advisable to
review their structure in <a class="reference internal" href="#deep-learning-models"><span class="std std-ref">Deep learning models</span></a>). The main structure
should be the same:</p>
<ul class="simple">
<li><p><strong>epochs</strong> (dict): Typical keys <strong>method</strong> (with value <code class="docutils literal notranslate"><span class="pre">randint</span></code>) and
<strong>values</strong> should be specified.</p></li>
<li><p><strong>layers</strong> (dict) Layer structure to benchmark; this key is the only one with
a completely different structure than specified in deep learning models; this
is because the approach for benchmarking them is through what are called
blocks. Blocks are a predefined combination of layers that will be shuffled
with a specific layer to generate combinations to benchmark. For example, one
block could be a linear layer + rectified linear unit, and another one could
be a dropout layer. The required structure is the following:</p>
<ul>
<li><p><strong>number_blocks</strong> (list): List of two values, which is the minimum and
maximum number of blocks considered for the models.</p></li>
<li><p><strong>types</strong> (list): List of strings that specify succession of layer types to
be considered as blocks, assuming that their names are contained within
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html">torch nn module</a>. Blocks that
contain a sequence of layers should join their names with the symbol <code class="docutils literal notranslate"><span class="pre">+</span></code>.</p></li>
<li><p><strong>params</strong> (dict, optional): In case some layer types require specific
parameters to be benchmarked, they should be informed within this key. The
structure to follow is the following:</p>
<ul>
<li><p><strong>{layer name}</strong> (str): Layer name, as specified in <strong>types</strong>.</p>
<ul>
<li><p><strong>{parameter name}</strong> (str): Name of parameter to be benchmarked. Its
internal structure should have the typical benchmark structure,
<strong>method</strong> and <strong>values</strong>.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>loader</strong>: (dict): Should still have both keys, <strong>batch_size</strong> and
<strong>shuffle</strong>, and each of them follow the standard benchmark structure
(<strong>method</strong> and <strong>values</strong>).</p></li>
<li><p><strong>loss</strong> (dict): Loss to consider; requires the following:</p>
<ul>
<li><p><strong>method</strong> (str): Should be equal to <code class="docutils literal notranslate"><span class="pre">choice</span></code>.</p></li>
<li><p><strong>values</strong> (list): For each possible option to consider, specify the
following:</p>
<ul>
<li><p><strong>module</strong> (str): Loss module.</p></li>
<li><p><strong>params</strong> (dict, optional): Parameters to benchmark for the specific
module, in case there are any. Each of them should have the standard
structure <strong>method</strong> and <strong>values</strong>.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>optimizer</strong> (dict): Optimizer to consider; requires the following:</p>
<ul>
<li><p><strong>method</strong> (str): Should be equal to <code class="docutils literal notranslate"><span class="pre">choice</span></code>.</p></li>
<li><p><strong>values</strong> (list): For each possible option to consider, specify the
following:</p>
<ul>
<li><p><strong>module</strong> (str): Optimizer module.</p></li>
<li><p><strong>params</strong> (dict, optional): Parameters to benchmark for the specific
module, in case there are any. Each of them should have the standard
structure <strong>method</strong> and <strong>values</strong>.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>An example of a benchmark configuration for deep learning models would be:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">benchmark</span><span class="p">:</span>
<span class="w">  </span><span class="nt">transform</span><span class="p">:</span>
<span class="w">    </span><span class="nt">models</span><span class="p">:</span>
<span class="w">      </span><span class="nt">torch</span><span class="p">:</span>
<span class="w">        </span><span class="nt">epochs</span><span class="p">:</span>
<span class="w">          </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">randint</span>
<span class="w">          </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">5</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">layers</span><span class="p">:</span>
<span class="w">          </span><span class="nt">number_blocks</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">3</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">6</span><span class="p p-Indicator">]</span>
<span class="w">          </span><span class="nt">types</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Linear + ReLU</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Dropout</span>
<span class="w">          </span><span class="nt">params</span><span class="p">:</span>
<span class="w">            </span><span class="nt">Dropout</span><span class="p">:</span>
<span class="w">              </span><span class="nt">p</span><span class="p">:</span>
<span class="w">                </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">uniform</span>
<span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.4</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.6</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">loader</span><span class="p">:</span>
<span class="w">          </span><span class="nt">batch_size</span><span class="p">:</span>
<span class="w">            </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">randint</span>
<span class="w">            </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">20</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">40</span><span class="p p-Indicator">]</span>
<span class="w">          </span><span class="nt">shuffle</span><span class="p">:</span>
<span class="w">            </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">choice</span>
<span class="w">            </span><span class="nt">values</span><span class="p">:</span>
<span class="w">              </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">              </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">        </span><span class="nt">loss</span><span class="p">:</span>
<span class="w">          </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">choice</span>
<span class="w">          </span><span class="nt">values</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.MSELoss</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.nn.L1Loss</span>
<span class="w">        </span><span class="nt">optimizer</span><span class="p">:</span>
<span class="w">          </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">choice</span>
<span class="w">          </span><span class="nt">values</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.optim.SGD</span>
<span class="w">              </span><span class="nt">params</span><span class="p">:</span>
<span class="w">                </span><span class="nt">lr</span><span class="p">:</span>
<span class="w">                  </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">loguniform</span>
<span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.001</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.01</span><span class="p p-Indicator">]</span>
<span class="w">                </span><span class="nt">momentum</span><span class="p">:</span>
<span class="w">                  </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">uniform</span>
<span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.5</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1</span><span class="p p-Indicator">]</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch.optim.Adam</span>
<span class="w">              </span><span class="nt">params</span><span class="p">:</span>
<span class="w">                </span><span class="nt">lr</span><span class="p">:</span>
<span class="w">                  </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">loguniform</span>
<span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.001</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.1</span><span class="p p-Indicator">]</span>
<span class="w">                </span><span class="nt">eps</span><span class="p">:</span>
<span class="w">                  </span><span class="nt">method</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">loguniform</span>
<span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.0000001</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.00001</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</section>
</section>
<section id="id21">
<h3>Load<a class="headerlink" href="#id21" title="Link to this heading">¶</a></h3>
<p>In load phase the possible configurations are the following:</p>
<ul class="simple">
<li><p><strong>path</strong> (str): Folder in which to store benchmark results.</p></li>
<li><p><strong>save_best_config_params</strong> (bool, optional): Whether to store a yaml file
with best model configuration or not, within specified <strong>path</strong>.</p></li>
</ul>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">HoNCAML</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="what.html">What is HoNCAML</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Configuration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#global">Global</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#benchmark">Benchmark</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="usage.html" title="previous chapter">Usage</a></li>
      <li>Next: <a href="reference.html" title="next chapter">Reference</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023, Eurecat.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/configuration.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>